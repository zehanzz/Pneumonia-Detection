{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true,
      "authorship_tag": "ABX9TyOzHOR8XqVO0yyEcfuJec4P",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zehanzz/Pneumonia_Detection/blob/main/Pneumonia_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "id": "4i0n6DxDG7xQ",
        "outputId": "8add5f78-84c3-485d-b28e-d0ebd489d7c3"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-5e937a26-25c3-4482-9b07-c1f02d025b7d\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-5e937a26-25c3-4482-9b07-c1f02d025b7d\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n",
            "Downloading chest-xray-pneumonia.zip to /content\n",
            "100% 2.29G/2.29G [01:24<00:00, 29.7MB/s]\n",
            "100% 2.29G/2.29G [01:24<00:00, 29.1MB/s]\n"
          ]
        }
      ],
      "source": [
        "!pip install -q kaggle\n",
        "from google.colab import files\n",
        "files.upload()\n",
        "!mkdir ~/.kaggle/\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!kaggle datasets download -d paultimothymooney/chest-xray-pneumonia"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip chest-xray-pneumonia.zip"
      ],
      "metadata": {
        "id": "MlNM1mEsKp4t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D , MaxPool2D , Flatten , Dropout , BatchNormalization\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report,confusion_matrix\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "import cv2"
      ],
      "metadata": {
        "id": "GsXuVJlGLXM4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = ['PNEUMONIA', 'NORMAL']\n",
        "img_size = 150\n",
        "def get_training_data(data_dir):\n",
        "    data = []\n",
        "    for label in labels:\n",
        "        path = os.path.join(data_dir, label)\n",
        "        class_num = labels.index(label)\n",
        "        for img in os.listdir(path):\n",
        "            try:\n",
        "                img_arr = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)\n",
        "                resized_arr = cv2.resize(img_arr, (img_size, img_size)) # Reshaping images to preferred size\n",
        "                data.append([resized_arr, class_num])\n",
        "            except Exception as e:\n",
        "                print(e)\n",
        "    return np.array(data)"
      ],
      "metadata": {
        "id": "UzhxFotFLpem"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "woUPm0iuLyHc",
        "outputId": "805e4fa0-e6d0-4211-af61-607bbc7975f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train = get_training_data('/content/chest_xray/chest_xray/train')\n",
        "test = get_training_data('/content/chest_xray/chest_xray/test')\n",
        "val = get_training_data('/content/chest_xray/chest_xray/val')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r7g7u624LukL",
        "outputId": "5864c3e6-187c-4f34-a06c-28585cd1e170"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OpenCV(4.7.0) /io/opencv/modules/imgproc/src/resize.cpp:4062: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n",
            "\n",
            "OpenCV(4.7.0) /io/opencv/modules/imgproc/src/resize.cpp:4062: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-b2613b36a4a4>:15: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  return np.array(data)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OpenCV(4.7.0) /io/opencv/modules/imgproc/src/resize.cpp:4062: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n",
            "\n",
            "OpenCV(4.7.0) /io/opencv/modules/imgproc/src/resize.cpp:4062: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = []\n",
        "y_train = []\n",
        "\n",
        "x_val = []\n",
        "y_val = []\n",
        "\n",
        "x_test = []\n",
        "y_test = []\n",
        "\n",
        "for feature, label in train:\n",
        "    x_train.append(feature)\n",
        "    y_train.append(label)\n",
        "\n",
        "for feature, label in test:\n",
        "    x_test.append(feature)\n",
        "    y_test.append(label)\n",
        "\n",
        "for feature, label in val:\n",
        "    x_val.append(feature)\n",
        "    y_val.append(label)"
      ],
      "metadata": {
        "id": "tefGBadHL2vB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize the data\n",
        "x_train = np.array(x_train) / 255\n",
        "x_val = np.array(x_val) / 255\n",
        "x_test = np.array(x_test) / 255"
      ],
      "metadata": {
        "id": "S_QecCi5MKwm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# resize data for deep learning\n",
        "x_train = x_train.reshape(-1, img_size, img_size, 1)\n",
        "y_train = np.array(y_train)\n",
        "\n",
        "x_val = x_val.reshape(-1, img_size, img_size, 1)\n",
        "y_val = np.array(y_val)\n",
        "\n",
        "x_test = x_test.reshape(-1, img_size, img_size, 1)\n",
        "y_test = np.array(y_test)"
      ],
      "metadata": {
        "id": "FHHEacPZMNeN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# With data augmentation to prevent overfitting and handling the imbalance in dataset\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "        samplewise_center=False,  # set each sample mean to 0\n",
        "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "        samplewise_std_normalization=False,  # divide each input by its std\n",
        "        zca_whitening=False,  # apply ZCA whitening\n",
        "        rotation_range = 30,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "        zoom_range = 0.2, # Randomly zoom image\n",
        "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
        "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
        "        horizontal_flip = True,  # randomly flip images\n",
        "        vertical_flip=False)  # randomly flip images\n",
        "\n",
        "\n",
        "datagen.fit(x_train)"
      ],
      "metadata": {
        "id": "tSJWP0dRMSej"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), strides=1, padding='same', activation='relu', input_shape=(150, 150, 1), name='conv2d_1'))\n",
        "model.add(BatchNormalization(name='batch_norm_1'))\n",
        "model.add(MaxPool2D((2, 2), strides=2, padding='same', name='maxpool_1'))\n",
        "model.add(Conv2D(64, (3, 3), strides=1, padding='same', activation='relu', name='conv2d_2'))\n",
        "model.add(Dropout(0.1, name='dropout_1'))\n",
        "model.add(BatchNormalization(name='batch_norm_2'))\n",
        "model.add(MaxPool2D((2, 2), strides=2, padding='same', name='maxpool_2'))\n",
        "model.add(Conv2D(64, (3, 3), strides=1, padding='same', activation='relu', name='conv2d_3'))\n",
        "model.add(BatchNormalization(name='batch_norm_3'))\n",
        "model.add(MaxPool2D((2, 2), strides=2, padding='same', name='maxpool_3'))\n",
        "model.add(Conv2D(128, (3, 3), strides=1, padding='same', activation='relu', name='conv2d_4'))\n",
        "model.add(Dropout(0.2, name='dropout_2'))\n",
        "model.add(BatchNormalization(name='batch_norm_4'))\n",
        "model.add(MaxPool2D((2, 2), strides=2, padding='same', name='maxpool_4'))\n",
        "model.add(Conv2D(256, (3, 3), strides=1, padding='same', activation='relu', name='conv2d_5'))\n",
        "model.add(Dropout(0.2, name='dropout_3'))\n",
        "model.add(BatchNormalization(name='batch_norm_5'))\n",
        "model.add(MaxPool2D((2, 2), strides=2, padding='same', name='maxpool_5'))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(units=128, activation='relu', name='dense_1'))\n",
        "model.add(Dropout(0.2, name='dropout_4'))\n",
        "model.add(Dense(units=1, activation='sigmoid', name='dense_2'))\n",
        "model.compile(optimizer=\"rmsprop\", loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pGxWrXUAMssZ",
        "outputId": "e4d2547c-1449-4c2e-f647-3590fb46b6c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_14\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_1 (Conv2D)           (None, 150, 150, 32)      320       \n",
            "                                                                 \n",
            " batch_norm_1 (BatchNormaliz  (None, 150, 150, 32)     128       \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " maxpool_1 (MaxPooling2D)    (None, 75, 75, 32)        0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 75, 75, 64)        18496     \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 75, 75, 64)        0         \n",
            "                                                                 \n",
            " batch_norm_2 (BatchNormaliz  (None, 75, 75, 64)       256       \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " maxpool_2 (MaxPooling2D)    (None, 38, 38, 64)        0         \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 38, 38, 64)        36928     \n",
            "                                                                 \n",
            " batch_norm_3 (BatchNormaliz  (None, 38, 38, 64)       256       \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " maxpool_3 (MaxPooling2D)    (None, 19, 19, 64)        0         \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 19, 19, 128)       73856     \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 19, 19, 128)       0         \n",
            "                                                                 \n",
            " batch_norm_4 (BatchNormaliz  (None, 19, 19, 128)      512       \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " maxpool_4 (MaxPooling2D)    (None, 10, 10, 128)       0         \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 10, 10, 256)       295168    \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 10, 10, 256)       0         \n",
            "                                                                 \n",
            " batch_norm_5 (BatchNormaliz  (None, 10, 10, 256)      1024      \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " maxpool_5 (MaxPooling2D)    (None, 5, 5, 256)         0         \n",
            "                                                                 \n",
            " flatten_14 (Flatten)        (None, 6400)              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 128)               819328    \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,246,401\n",
            "Trainable params: 1,245,313\n",
            "Non-trainable params: 1,088\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tqdm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rTyfSXOhaqjX",
        "outputId": "209ca82b-02ac-40cc-859a-0db37328c9d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.65.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def apply_selective_feature_dropping(model, images, labels, drop_ratio=0.2, keep_ratio=0.2):\n",
        "    with tf.GradientTape() as tape:\n",
        "\n",
        "        tape.watch(images)\n",
        "\n",
        "        outputs = model(images, training=True)\n",
        "\n",
        "        labels = tf.reshape(labels, (-1, 1))\n",
        "        loss = tf.keras.losses.binary_crossentropy(labels, outputs)\n",
        "\n",
        "    grads = tape.gradient(loss, images)\n",
        "\n",
        "    norm_grads = tf.norm(grads, axis=-1)\n",
        "\n",
        "    norm_grads_flat = tf.reshape(norm_grads, [tf.shape(norm_grads)[0], -1])\n",
        "\n",
        "    total_features = np.prod(images.shape[1:4])\n",
        "\n",
        "    keep_features = int(keep_ratio * total_features)\n",
        "    drop_features = int(drop_ratio * total_features)\n",
        "\n",
        "    sorted_values, sorted_indices = tf.math.top_k(norm_grads_flat, k=total_features)\n",
        "\n",
        "    drop_indices = sorted_indices[:, keep_features:keep_features+drop_features]\n",
        "\n",
        "    mask = tf.ones_like(norm_grads_flat)\n",
        "\n",
        "    batch_indices = tf.reshape(\n",
        "        tf.repeat(tf.range(tf.shape(norm_grads_flat)[0]), tf.shape(drop_indices)[1]), (-1, 1)\n",
        "    )\n",
        "    scatter_indices = tf.concat([batch_indices, tf.reshape(drop_indices, (-1, 1))], axis=1)\n",
        "\n",
        "    mask = tf.tensor_scatter_nd_update(mask, scatter_indices, tf.zeros(tf.shape(scatter_indices)[0]))\n",
        "\n",
        "    mask = tf.reshape(mask, tf.shape(images))\n",
        "\n",
        "    masked_images = tf.multiply(images, mask)\n",
        "\n",
        "    return masked_images"
      ],
      "metadata": {
        "id": "SvhqSzx64F5h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "\n",
        "learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', patience=2, verbose=1, factor=0.3, min_lr=0.000001)\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "learning_rate_reduction.set_model(model)\n",
        "\n",
        "feature_ratio = 0.065\n",
        "\n",
        "def apply_feature_dropping(model, images, labels):\n",
        "    with tf.GradientTape() as tape:\n",
        "\n",
        "        tape.watch(images)\n",
        "\n",
        "        outputs = model(images, training=True)\n",
        "\n",
        "        labels = tf.reshape(labels, (-1, 1))\n",
        "        loss = tf.keras.losses.binary_crossentropy(labels, outputs)\n",
        "\n",
        "    grads = tape.gradient(loss, images)\n",
        "\n",
        "    norm_grads = tf.norm(grads, axis=-1)\n",
        "\n",
        "    norm_grads_flat = tf.reshape(norm_grads, [tf.shape(norm_grads)[0], -1])\n",
        "\n",
        "    neg_norm_grads_flat = -norm_grads_flat\n",
        "\n",
        "    _, idx_mask = tf.math.top_k(neg_norm_grads_flat, k=int(feature_ratio * np.prod(images.shape[1:4])), sorted=False)\n",
        "\n",
        "    mask = tf.ones_like(norm_grads_flat)\n",
        "\n",
        "    batch_indices = tf.reshape(\n",
        "        tf.repeat(tf.range(tf.shape(norm_grads_flat)[0]), tf.shape(idx_mask)[1]), (-1, 1)\n",
        "    )\n",
        "    scatter_indices = tf.concat([batch_indices, tf.reshape(idx_mask, (-1, 1))], axis=1)\n",
        "\n",
        "    mask = tf.tensor_scatter_nd_update(mask, scatter_indices, tf.zeros(tf.shape(scatter_indices)[0]))\n",
        "\n",
        "    mask = tf.reshape(mask, tf.shape(images))\n",
        "\n",
        "    masked_images = tf.multiply(images, mask)\n",
        "\n",
        "    return masked_images\n",
        "\n",
        "\n",
        "epochs = 12\n",
        "num_batches = len(x_train) // 32  # assuming batch_size of 32\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    print(f\"Starting Epoch {epoch + 1}/{epochs}\")\n",
        "\n",
        "    train_losses = []\n",
        "    train_accuracies = []\n",
        "\n",
        "    pbar = tqdm(total=num_batches, ncols=70)\n",
        "\n",
        "    for i, (batch_x, batch_y) in enumerate(datagen.flow(x_train, y_train, batch_size=32)):\n",
        "        batch_x = tf.convert_to_tensor(batch_x, dtype=tf.float32)\n",
        "\n",
        "        batch_y = tf.convert_to_tensor(batch_y, dtype=tf.float32)\n",
        "\n",
        "        masked_images = apply_feature_dropping(model, batch_x, batch_y)\n",
        "\n",
        "        loss, acc = model.train_on_batch(masked_images, batch_y)\n",
        "\n",
        "        train_losses.append(loss)\n",
        "        train_accuracies.append(acc)\n",
        "\n",
        "        pbar.set_description(f'Epoch {epoch + 1}/{epochs}, Train Accuracy: {np.mean(train_accuracies):.4f}')\n",
        "        pbar.update()\n",
        "\n",
        "        if i + 1 == num_batches:\n",
        "            break\n",
        "\n",
        "    pbar.close()\n",
        "\n",
        "    avg_train_loss = np.mean(train_losses)\n",
        "    avg_train_acc = np.mean(train_accuracies)\n",
        "\n",
        "    val_loss, val_acc = model.evaluate(datagen.flow(x_val, y_val), verbose=0)\n",
        "\n",
        "    learning_rate_reduction.on_epoch_end(epoch, {\"val_accuracy\": val_acc})\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}/{epochs}, Train Accuracy: {avg_train_acc:.4f}, Validation Accuracy: {val_acc:.4f}\")\n",
        "\n",
        "print(\"Training completed!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "4qNEAAc4RxSE",
        "outputId": "82bb5318-938e-42d7-fb9f-6fa4ffdaa577"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-499d357f6881>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImageDataGenerator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mReduceLROnPlateau\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotebook\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    474\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_current_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"keras\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 476\u001b[0;31m     \u001b[0m_keras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    477\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/lazy_loader.py\u001b[0m in \u001b[0;36m_load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;34m\"\"\"Load the module and insert it into the parent's globals.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;31m# Import the target module and insert it into the parent's namespace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_module_globals\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_local_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    124\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \"\"\"\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdistribute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_layer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequential\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/models/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFunctional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequential\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/functional.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtensor\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlayout_map\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mlayout_map_lib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbase_layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/backend.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdistribute_coordinator_utils\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtensor\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdtensor_api\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdtensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras_tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcontrol_flow_util\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mobject_identity\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/keras_tensor.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mobject_identity\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# isort: off\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;31m# Preprocessing utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_space\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFeatureSpace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;31m# Internal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/feature_space.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbase_layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaving\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msaving_lib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaving\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mserialization_lib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mregularizers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtensor\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlazy_variable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbase_layer_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minput_spec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras_tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mget_code\u001b[0;34m(self, fullname)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36m_compile_bytecode\u001b[0;34m(data, name, bytecode_path, source_path)\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "import tensorflow as tf\n",
        "\n",
        "# Define the learning rate reduction callback\n",
        "learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', patience=2, verbose=1, factor=0.3, min_lr=0.000001)\n"
      ],
      "metadata": {
        "id": "zcreBeyS42ll"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess data and calculate Grad-CAM heatmaps outside the training loop\n",
        "train_heatmaps = []\n",
        "train_masks = []\n",
        "for img in x_train:\n",
        "    heatmap, masked_image = apply_grad_cam(model2, img, layer_name='conv2d_5', class_index=0)\n",
        "    train_heatmaps.append(heatmap)\n",
        "    train_masks.append(masked_image)"
      ],
      "metadata": {
        "id": "48_7DPzUmPzi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train_masks))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ppicQMW_CBN",
        "outputId": "ea800ee6-67e7-4753-f1da-09dd3973a409"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5216\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_masks.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0R4qcEcY-Jew",
        "outputId": "3f80552d-10de-4d78-cc77-4a6e83dd55f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5216, 150, 150, 1, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_heatmaps_gray = np.array([cv2.cvtColor(heatmap, cv2.COLOR_RGB2GRAY) for heatmap in train_heatmaps])\n",
        "heatmap_threshold = np.percentile(train_heatmaps_gray, 0)\n",
        "train_masks = np.array(train_masks) * (train_heatmaps_gray > heatmap_threshold)\n",
        "train_masks = np.expand_dims(train_masks, axis=-1)"
      ],
      "metadata": {
        "id": "sDcMxk26zdmV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(heatmap_threshold)\n",
        "print(np.min(train_heatmaps_gray))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F8bYg8hi_Tp9",
        "outputId": "048d4cac-1596-4f52-aa76-c6b2f9e5082f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7.296000003814697\n",
            "7.296\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, verbose=1, restore_best_weights=True)\n",
        "\n",
        "# history = model2.fit(datagen.flow(train_masks, y_train, batch_size=32),\n",
        "#                     steps_per_epoch=len(train_masks) // 32,\n",
        "#                     epochs=20,\n",
        "#                     validation_data=datagen.flow(x_val, y_val),\n",
        "#                     callbacks=[learning_rate_reduction, early_stopping])\n",
        "\n",
        "history = model2.fit(x=train_masks,\n",
        "                     y=y_train,\n",
        "                     batch_size=32,\n",
        "                     epochs=20,\n",
        "                     validation_data=(x_val, y_val),\n",
        "                     callbacks=[learning_rate_reduction, early_stopping])\n",
        "\n",
        "print(\"Training completed!\")"
      ],
      "metadata": {
        "id": "zEAhPZ-YqtRv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model2.fit(datagen.flow(x_train, y_train, batch_size=32) ,epochs = 12 , validation_data = datagen.flow(x_val, y_val) ,callbacks = [learning_rate_reduction])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 644
        },
        "id": "PSUgVD2VxmGS",
        "outputId": "3a656717-482d-455b-fa73-588e69360e15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/12\n",
            "163/163 [==============================] - 15s 68ms/step - loss: 0.5613 - accuracy: 0.8276 - val_loss: 19.5662 - val_accuracy: 0.5000 - lr: 0.0010\n",
            "Epoch 2/12\n",
            "163/163 [==============================] - 11s 69ms/step - loss: 0.2689 - accuracy: 0.8955 - val_loss: 38.9285 - val_accuracy: 0.5000 - lr: 0.0010\n",
            "Epoch 3/12\n",
            "163/163 [==============================] - ETA: 0s - loss: 0.2381 - accuracy: 0.9162\n",
            "Epoch 3: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "163/163 [==============================] - 11s 69ms/step - loss: 0.2381 - accuracy: 0.9162 - val_loss: 14.6160 - val_accuracy: 0.5000 - lr: 0.0010\n",
            "Epoch 4/12\n",
            "163/163 [==============================] - 12s 73ms/step - loss: 0.1631 - accuracy: 0.9410 - val_loss: 29.1275 - val_accuracy: 0.5000 - lr: 3.0000e-04\n",
            "Epoch 5/12\n",
            "163/163 [==============================] - ETA: 0s - loss: 0.1410 - accuracy: 0.9515\n",
            "Epoch 5: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "163/163 [==============================] - 11s 69ms/step - loss: 0.1410 - accuracy: 0.9515 - val_loss: 4.6792 - val_accuracy: 0.5000 - lr: 3.0000e-04\n",
            "Epoch 6/12\n",
            "163/163 [==============================] - 10s 61ms/step - loss: 0.1197 - accuracy: 0.9574 - val_loss: 0.4719 - val_accuracy: 0.8125 - lr: 9.0000e-05\n",
            "Epoch 7/12\n",
            "163/163 [==============================] - 11s 69ms/step - loss: 0.1015 - accuracy: 0.9617 - val_loss: 0.6447 - val_accuracy: 0.8125 - lr: 9.0000e-05\n",
            "Epoch 8/12\n",
            "163/163 [==============================] - ETA: 0s - loss: 0.1182 - accuracy: 0.9620\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 2.700000040931627e-05.\n",
            "163/163 [==============================] - 11s 69ms/step - loss: 0.1182 - accuracy: 0.9620 - val_loss: 15.4713 - val_accuracy: 0.5000 - lr: 9.0000e-05\n",
            "Epoch 9/12\n",
            "163/163 [==============================] - 11s 69ms/step - loss: 0.1058 - accuracy: 0.9628 - val_loss: 0.4191 - val_accuracy: 0.8125 - lr: 2.7000e-05\n",
            "Epoch 10/12\n",
            "163/163 [==============================] - ETA: 0s - loss: 0.1096 - accuracy: 0.9643\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 8.100000013655517e-06.\n",
            "163/163 [==============================] - 12s 76ms/step - loss: 0.1096 - accuracy: 0.9643 - val_loss: 2.0918 - val_accuracy: 0.5000 - lr: 2.7000e-05\n",
            "Epoch 11/12\n",
            "163/163 [==============================] - 11s 68ms/step - loss: 0.1006 - accuracy: 0.9651 - val_loss: 1.0708 - val_accuracy: 0.5625 - lr: 8.1000e-06\n",
            "Epoch 12/12\n",
            "163/163 [==============================] - ETA: 0s - loss: 0.1074 - accuracy: 0.9611\n",
            "Epoch 12: ReduceLROnPlateau reducing learning rate to 2.429999949526973e-06.\n",
            "163/163 [==============================] - 10s 61ms/step - loss: 0.1074 - accuracy: 0.9611 - val_loss: 0.8075 - val_accuracy: 0.7500 - lr: 8.1000e-06\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Loss of the model is - \" , model.evaluate(x_test,y_test)[0])\n",
        "print(\"Accuracy of the model is - \" , model.evaluate(x_test,y_test)[1]*100 , \"%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NX9uI6IisURc",
        "outputId": "63f3d4e2-5052-4eb5-e3b2-f8aaafba86ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20/20 [==============================] - 0s 7ms/step - loss: 1.5558 - accuracy: 0.6554\n",
            "Loss of the model is -  1.5557632446289062\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 1.5558 - accuracy: 0.6554\n",
            "Accuracy of the model is -  65.54487347602844 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('my_model.h5')"
      ],
      "metadata": {
        "id": "iXdo2yDOtLlE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}